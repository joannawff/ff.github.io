{"pages":[],"posts":[{"title":"My Love","text":"What if I die before you? Continue my life. (Silence) Disappointed? Yeah. I need give our parents the end of their care. (Silence) I would try to die before you. I’m afraid nobody would take care of our parents then. (Silence) If you’ve got cancer, let’s resign and go traverling around the world with all of our belongings. OK.","link":"/2021/05/22/2021-05-22/"},{"title":"BERT and its family","text":"Reference: https://wmathor.com/index.php/archives/1508/","link":"/2021/05/19/BERT-and-its-family/"},{"title":"Roberta","text":"","link":"/2021/05/19/Roberta/"},{"title":"Word2Vec vs BPE vs WordPiece","text":"Reference: https://wmathor.com/index.php/archives/1517/","link":"/2021/05/19/BPE-vs-WordPiece/"},{"title":"Open Corpora","text":"https://github.com/LDNOOBW/List-of-Dirty-Naughty-Obscene-and-Otherwise-Bad-Words","link":"/2021/05/25/Open-Corpora/"},{"title":"data-quality.md","text":"","link":"/2021/03/11/data-quality-md/"},{"title":"Data quality or model quality?","text":"[https://www.talend.com/resources/machine-learning-data-quality/](https://www.talend.com/resources/machine-learning-data-quality/","link":"/2021/03/11/data-quality/"},{"title":"Get Start with Hexo","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/2021/02/27/hello-world/"},{"title":"Multilingual Pretrained Models","text":"","link":"/2021/02/27/multilingual-pretrained-models/"},{"title":"language detect","text":"resource: https://pypi.org/project/langdetect/","link":"/2021/05/25/language-detect/"},{"title":"photo","text":"","link":"/2021/03/11/photo/"},{"title":"wide&deep bert","text":"How to integrate traditional models like GBDT/LR to popular transformer based pretrain-finetune models like BERT/Roberta? Please Reference: Modeling Relevance Ranking under the Pre-training and Fine-tuning Paradigm GBDT and BERT: a Hybrid Solution for Recognizing Citation Intent Wide And Deep Transformers Applied to Semantic Relatedness and Textual Entailment","link":"/2021/11/02/wide-deep-bert/"},{"title":"Lean about Huggingface Transformers","text":"","link":"/2021/02/27/transformers/"},{"title":"Model Compression","text":"Methods: Network Pruning Knowledge Distillation Parameter Quantization Architecture Design Reference: http://mitchgordon.me/machine/learning/2019/11/18/all-the-ways-to-compress-BERT.html https://www.bilibili.com/video/BV1yy4y1B7ny/ https://wmathor.com/index.php/archives/1508/","link":"/2021/05/19/Model-Compression/"},{"title":"Linux Commands","text":"Please click linux-command to view more commands.","link":"/2021/03/03/linux-commands/"},{"title":"What does NLTK do?","text":"Language processing tasks and corresponding NLTK modules with examples of functionality Language processing task NLTK modules Functionality Accessing corpora corpus standardized interfaces to corpora and lexicons String processing tokenize, stem tokenizers, sentence tokenizers, stemmers Collocation discovery collocations t-test, chi-squared, point-wise mutual information Part-of-speech tagging tag n-gram, backoff, Brill, HMM, TnT Machine learning classify, cluster, tbl decision tree, maximum entropy, naive Bayes, EM, k-means Chunking chunk regular expression, n-gram, named-entity Parsing parse, ccg chart, feature-based, unification, probabilistic, dependency Semantic interpretation sem, inference lambda calculus, first-order logic, model checking Evaluation metrics metrics precision, recall, agreement coefficients Probability and estimation probability frequency distributions, smoothed probability distributions Applications app, chat graphical concordancer, parsers, WordNet browser, chatbots Linguistic fieldwork toolbox manipulate data in SIL Toolbox format Referencehttps://www.nltk.org/book/ch00.html#tab-goals","link":"/2021/11/03/nltk-overview/"}],"tags":[{"name":"diary","slug":"diary","link":"/tags/diary/"},{"name":"NLP,Transformer","slug":"NLP-Transformer","link":"/tags/NLP-Transformer/"},{"name":"NLP, ML, DL, data analysis","slug":"NLP-ML-DL-data-analysis","link":"/tags/NLP-ML-DL-data-analysis/"},{"name":"nlp","slug":"nlp","link":"/tags/nlp/"},{"name":"NLP","slug":"NLP","link":"/tags/NLP/"},{"name":"linux","slug":"linux","link":"/tags/linux/"}],"categories":[]}